{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DriZqOtrly1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from google.colab import drive as google\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ix1anRqqrmvh"
      },
      "outputs": [],
      "source": [
        "google.mount(\"/content/Drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMu85dL1ruTe"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Attention Gate\n",
        "def attention_block(x, g, inter_channels):\n",
        "    theta_x = layers.Conv2D(inter_channels, 1, strides=1, padding='same')(x)\n",
        "    phi_g = layers.Conv2D(inter_channels, 1, strides=1, padding='same')(g)\n",
        "    add = layers.Add()([theta_x, phi_g])\n",
        "    act = layers.Activation('relu')(add)\n",
        "    psi = layers.Conv2D(1, 1, strides=1, padding='same', activation='sigmoid')(act)\n",
        "    return layers.Multiply()([x, psi])\n",
        "\n",
        "# U-Net with Attention for Classification\n",
        "def unet_attention(input_shape, num_classes):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
        "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    # Bottleneck\n",
        "    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
        "    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
        "\n",
        "    # Decoder with Attention Blocks\n",
        "    up3 = layers.Conv2DTranspose(256, kernel_size=2, strides=2, padding=\"same\")(conv4)\n",
        "    att3 = attention_block(conv3, up3, 256)\n",
        "    merge3 = layers.Concatenate()([att3, up3])\n",
        "    conv5 = layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\")(merge3)\n",
        "\n",
        "    up2 = layers.Conv2DTranspose(128, kernel_size=2, strides=2, padding=\"same\")(conv5)\n",
        "    att2 = attention_block(conv2, up2, 128)\n",
        "    merge2 = layers.Concatenate()([att2, up2])\n",
        "    conv6 = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(merge2)\n",
        "\n",
        "    up1 = layers.Conv2DTranspose(64, kernel_size=2, strides=2, padding=\"same\")(conv6)\n",
        "    att1 = attention_block(conv1, up1, 64)\n",
        "    merge1 = layers.Concatenate()([att1, up1])\n",
        "    conv7 = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(merge1)\n",
        "\n",
        "\n",
        "    # Classification Head\n",
        "    gap = layers.GlobalAveragePooling2D()(conv7)\n",
        "    output = layers.Dense(num_classes, activation='softmax')(gap)\n",
        "\n",
        "    model = keras.Model(inputs, output)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMI6IexfryyI"
      },
      "outputs": [],
      "source": [
        "# Define model\n",
        "input_shape = (256, 256, 3)  # Adjust size based on your MRI dataset\n",
        "num_classes = 4  # (3 tumor types + 1 no tumor)\n",
        "model = unet_attention(input_shape, num_classes)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam',\n",
        "               loss='categorical_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "# Data loading and augmentation\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFcvWmbHsCdn"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_file(zip_path, extract_to='.'):\n",
        "    \"\"\"\n",
        "    Unzips a file to the specified directory.\n",
        "\n",
        "    Parameters:\n",
        "    zip_path (str): Path to the zip file.\n",
        "    extract_to (str): Directory where the files should be extracted. Default is the current directory.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_to)\n",
        "        print(f\"Extracted files to: {os.path.abspath(extract_to)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "unzip_file('/content/Drive/MyDrive/brain tumor.zip', '/content/braintumor_folder')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKgWyeMdsOSN"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 256\n",
        "TRAIN_DIR = \"/content/braintumor_folder/Training\"\n",
        "TEST_DIR = \"/content/braintumor_folder/Testing\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsKAP5MAsSbJ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "training_dataset = train_datagen.flow_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    target_size = (IMG_SIZE,IMG_SIZE),\n",
        "    batch_size = 32,\n",
        "    class_mode = \"categorical\",\n",
        "    shuffle = True\n",
        ")\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_dataset = test_datagen.flow_from_directory(\n",
        "    TEST_DIR,\n",
        "    target_size = (IMG_SIZE,IMG_SIZE),\n",
        "    batch_size = 32,\n",
        "    class_mode = \"categorical\",\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "training_dataset.class_indices\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LmM_tjv2yhk"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Get a batch of images and labels\n",
        "images, labels = next(training_dataset)  # Get one batch (32 images in this case)\n",
        "\n",
        "# Get class names from class indices\n",
        "class_labels = {v: k for k, v in training_dataset.class_indices.items()}  # Reverse the dictionary\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):  # Show 9 images\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i])  # Images are already rescaled\n",
        "    label_index = np.argmax(labels[i])  # Get the class index\n",
        "    plt.title(class_labels[label_index])  # Show class name\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlXDW-M3sq4D"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "class StopOnAccuracy(Callback):\n",
        "  def __init__(self,target_acc=0.98):\n",
        "    super(StopOnAccuracy, self).__init__()\n",
        "    self.target_acc = target_acc\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    logs = logs or {}\n",
        "    if logs.get('accuracy')>=self.target_acc:\n",
        "      print(f\"\\nReached {self.target_acc} , so the training is being stopped\\n\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "stop_on_accuracy = StopOnAccuracy(target_acc=0.96)\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(patience= 15, monitor=\"val_loss\", restore_best_weights = True, verbose = 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "do8N-ctQ2_fY"
      },
      "outputs": [],
      "source": [
        "print(model.to_json())  # Useful for saving/loading architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbUEyL8P3Bxg"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIEj8pFe3cTt"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kVBYHR-tK3h"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    training_dataset,\n",
        "    epochs = 100,\n",
        "    validation_data = test_dataset,\n",
        "    batch_size = 32,\n",
        "    validation_steps = int(0.25*len(test_dataset)),\n",
        "    callbacks = [stop_on_accuracy,early_stopping,tf.keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True)]\n",
        ")\n",
        "model.save(\"/content/Drive/MyDrive/finalfinalfinalp2.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OPB5Kt3tXJl"
      },
      "outputs": [],
      "source": [
        "model.save(\"/content/Drive/MyDrive/finalfinalfinalp2.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3W4b5ddHrMY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_acc = history.history[\"accuracy\"]\n",
        "test_acc = history.history[\"val_accuracy\"]\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "epochs_range = range(1,44)\n",
        "\n",
        "plt.figure(figsize=(18,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs_range,train_acc,label=\"Training Accuracy\",marker=\"o\")\n",
        "plt.plot(epochs_range,test_acc,label=\"Validation Accuracy\",marker=\"o\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training v/s Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.figure(figsize=(18,5))\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs_range,loss,label = \"Training_loss\",marker=\"o\")\n",
        "plt.plot(epochs_range,val_loss, label=\"Validation_loss\",marker=\"o\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training v/s Validation loss\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPchCdkB-HaQ"
      },
      "outputs": [],
      "source": [
        "model_x = tf.keras.models.load_model(\"/content/Drive/MyDrive/finalfinalfinalp2.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_x.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "x9Q_w7HqH81B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Class labels\n",
        "class_names = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "    # Optional: print classification report\n",
        "    print(\"\\nClassification Report:\\n\")\n",
        "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "\n",
        "plot_confusion_matrix(test_dataset.classes, np.argmax(model_x.predict(test_dataset), axis=-1))"
      ],
      "metadata": {
        "id": "CvRhAjPxIC4E"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
